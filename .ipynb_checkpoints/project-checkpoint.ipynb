{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from glrlm import GLRLM\n",
    "import numpy as np \n",
    "import cv2 \n",
    "import os\n",
    "import re\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Utility functions ------------------------\n",
    "def normalize_label(str_):\n",
    "    str_ = str_.replace(\" \", \"\")\n",
    "    str_ = str_.translate(str_.maketrans(\"\",\"\", \"()\"))\n",
    "    str_ = str_.split(\"_\")\n",
    "    return ''.join(str_[:2])\n",
    "\n",
    "def normalize_desc(folder, sub_folder):\n",
    "    text = folder + \" - \" + sub_folder \n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.replace(\".\", \"\")\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def print_progress(val, val_len, folder, sub_folder, filename, bar_size=10):\n",
    "    progr = \"#\"*round((val)*bar_size/val_len) + \" \"*round((val_len - (val))*bar_size/val_len)\n",
    "    if val == 0:\n",
    "        print(\"\", end = \"\\n\")\n",
    "    else:\n",
    "        print(\"[%s] folder : %s/%s/ ----> file : %s\" % (progr, folder, sub_folder, filename), end=\"\\r\")\n",
    "        \n",
    "\n",
    "# -------------------- Load Dataset ------------------------\n",
    " \n",
    "\n",
    "\n",
    "imgs = [] #list image matrix   \n",
    "labels = []\n",
    "descs = []\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset/Healthy/\" \n",
    "for filename in os.listdir(dataset_dir):\n",
    "    img = cv2.imread(os.path.join(dataset_dir, filename))\n",
    "    img_median2 = cv2.medianBlur(img, 5)\n",
    "    gray = cv2.cvtColor(img_median2, cv2.COLOR_BGR2GRAY)\n",
    "    h, w = gray.shape\n",
    "    ymin, ymax, xmin, xmax = h//3, h*2//3, w//3, w*2//3\n",
    "    crop = gray[ymin:ymax, xmin:xmax]\n",
    "\n",
    "    resize = cv2.resize(crop, (0,0), fx=0.5, fy=0.5)\n",
    "    ret, resize = cv2.threshold(resize, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    imgs.append(resize)\n",
    "    labels.append(1)\n",
    "            \n",
    "#             print_progress(i, len_sub_folder, folder, sub_folder, filename)\n",
    "\n",
    "# ----------------- calculate greycomatrix() & greycoprops() for angle 0, 45, 90, 135 ----------------------------------\n",
    "def calc_glcm_all_agls(img, label, props, dists=[5], agls=[0, np.pi/4, np.pi/2, 3*np.pi/4], lvl=256, sym=True, norm=True):\n",
    "    \n",
    "    glcm = greycomatrix(img, \n",
    "                        distances=dists, \n",
    "                        angles=agls, \n",
    "                        levels=lvl,\n",
    "                        symmetric=sym, \n",
    "                        normed=norm)\n",
    "    feature = []\n",
    "    glcm_props = [propery for name in props for propery in greycoprops(glcm, name)[0]]\n",
    "    for item in glcm_props:\n",
    "            feature.append(item)\n",
    "    feature.append(label) \n",
    "    return feature\n",
    "\n",
    "\n",
    "# ----------------- call calc_glcm_all_agls() for all properties ----------------------------------\n",
    "properties = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'ASM', 'energy']\n",
    "\n",
    "glcm_all_agls = []\n",
    "for img, label in zip(imgs, labels): \n",
    "    glcm_all_agls.append(\n",
    "            calc_glcm_all_agls(img, \n",
    "                                label, \n",
    "                                props=properties)\n",
    "                            )\n",
    " \n",
    "columns = []\n",
    "angles = ['0', '45', '90','135']\n",
    "for name in properties :\n",
    "    for ang in angles:\n",
    "        columns.append(name + \"_\" + ang)\n",
    "        \n",
    "columns.append(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Create the pandas DataFrame for GLCM features data\n",
    "glcm_df = pd.DataFrame(glcm_all_agls, \n",
    "                      columns = columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dissimilarity_0</th>\n",
       "      <th>dissimilarity_45</th>\n",
       "      <th>dissimilarity_90</th>\n",
       "      <th>dissimilarity_135</th>\n",
       "      <th>correlation_0</th>\n",
       "      <th>correlation_45</th>\n",
       "      <th>correlation_90</th>\n",
       "      <th>correlation_135</th>\n",
       "      <th>homogeneity_0</th>\n",
       "      <th>homogeneity_45</th>\n",
       "      <th>...</th>\n",
       "      <th>contrast_135</th>\n",
       "      <th>ASM_0</th>\n",
       "      <th>ASM_45</th>\n",
       "      <th>ASM_90</th>\n",
       "      <th>ASM_135</th>\n",
       "      <th>energy_0</th>\n",
       "      <th>energy_45</th>\n",
       "      <th>energy_90</th>\n",
       "      <th>energy_135</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.022545</td>\n",
       "      <td>37.420513</td>\n",
       "      <td>28.835832</td>\n",
       "      <td>34.987897</td>\n",
       "      <td>0.605575</td>\n",
       "      <td>0.591226</td>\n",
       "      <td>0.684692</td>\n",
       "      <td>0.617800</td>\n",
       "      <td>0.858737</td>\n",
       "      <td>0.853255</td>\n",
       "      <td>...</td>\n",
       "      <td>8921.913788</td>\n",
       "      <td>0.520537</td>\n",
       "      <td>0.515794</td>\n",
       "      <td>0.541067</td>\n",
       "      <td>0.522625</td>\n",
       "      <td>0.721482</td>\n",
       "      <td>0.718188</td>\n",
       "      <td>0.735573</td>\n",
       "      <td>0.722928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.824324</td>\n",
       "      <td>22.505369</td>\n",
       "      <td>18.579508</td>\n",
       "      <td>21.504477</td>\n",
       "      <td>0.828589</td>\n",
       "      <td>0.823273</td>\n",
       "      <td>0.854096</td>\n",
       "      <td>0.831132</td>\n",
       "      <td>0.914416</td>\n",
       "      <td>0.911745</td>\n",
       "      <td>...</td>\n",
       "      <td>5483.641666</td>\n",
       "      <td>0.422439</td>\n",
       "      <td>0.420140</td>\n",
       "      <td>0.433072</td>\n",
       "      <td>0.423388</td>\n",
       "      <td>0.649953</td>\n",
       "      <td>0.648182</td>\n",
       "      <td>0.658082</td>\n",
       "      <td>0.650683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.298588</td>\n",
       "      <td>28.204032</td>\n",
       "      <td>23.367413</td>\n",
       "      <td>26.434295</td>\n",
       "      <td>0.738198</td>\n",
       "      <td>0.729687</td>\n",
       "      <td>0.775990</td>\n",
       "      <td>0.746654</td>\n",
       "      <td>0.892948</td>\n",
       "      <td>0.889398</td>\n",
       "      <td>...</td>\n",
       "      <td>6740.745118</td>\n",
       "      <td>0.495497</td>\n",
       "      <td>0.492460</td>\n",
       "      <td>0.507685</td>\n",
       "      <td>0.497902</td>\n",
       "      <td>0.703916</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.712520</td>\n",
       "      <td>0.705622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.113767</td>\n",
       "      <td>41.475130</td>\n",
       "      <td>36.150976</td>\n",
       "      <td>43.111441</td>\n",
       "      <td>0.655680</td>\n",
       "      <td>0.668513</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>0.655432</td>\n",
       "      <td>0.830929</td>\n",
       "      <td>0.837355</td>\n",
       "      <td>...</td>\n",
       "      <td>10993.417514</td>\n",
       "      <td>0.368477</td>\n",
       "      <td>0.373147</td>\n",
       "      <td>0.387611</td>\n",
       "      <td>0.368861</td>\n",
       "      <td>0.607023</td>\n",
       "      <td>0.610858</td>\n",
       "      <td>0.622584</td>\n",
       "      <td>0.607339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.773281</td>\n",
       "      <td>46.187211</td>\n",
       "      <td>45.491846</td>\n",
       "      <td>49.994699</td>\n",
       "      <td>0.626393</td>\n",
       "      <td>0.631317</td>\n",
       "      <td>0.636999</td>\n",
       "      <td>0.600923</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.818876</td>\n",
       "      <td>...</td>\n",
       "      <td>12748.648332</td>\n",
       "      <td>0.359264</td>\n",
       "      <td>0.360401</td>\n",
       "      <td>0.361970</td>\n",
       "      <td>0.351103</td>\n",
       "      <td>0.599386</td>\n",
       "      <td>0.600334</td>\n",
       "      <td>0.601639</td>\n",
       "      <td>0.592539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>21.459527</td>\n",
       "      <td>23.200347</td>\n",
       "      <td>27.332451</td>\n",
       "      <td>27.909334</td>\n",
       "      <td>0.830504</td>\n",
       "      <td>0.816781</td>\n",
       "      <td>0.784110</td>\n",
       "      <td>0.779593</td>\n",
       "      <td>0.915846</td>\n",
       "      <td>0.909020</td>\n",
       "      <td>...</td>\n",
       "      <td>7116.880096</td>\n",
       "      <td>0.426427</td>\n",
       "      <td>0.420723</td>\n",
       "      <td>0.407819</td>\n",
       "      <td>0.405956</td>\n",
       "      <td>0.653014</td>\n",
       "      <td>0.648632</td>\n",
       "      <td>0.638607</td>\n",
       "      <td>0.637147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>8.840554</td>\n",
       "      <td>11.883463</td>\n",
       "      <td>12.704092</td>\n",
       "      <td>11.241469</td>\n",
       "      <td>0.929968</td>\n",
       "      <td>0.905865</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>0.910951</td>\n",
       "      <td>0.965332</td>\n",
       "      <td>0.953399</td>\n",
       "      <td>...</td>\n",
       "      <td>2866.574569</td>\n",
       "      <td>0.471493</td>\n",
       "      <td>0.460515</td>\n",
       "      <td>0.457784</td>\n",
       "      <td>0.462804</td>\n",
       "      <td>0.686654</td>\n",
       "      <td>0.678613</td>\n",
       "      <td>0.676597</td>\n",
       "      <td>0.680297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>29.494681</td>\n",
       "      <td>33.564682</td>\n",
       "      <td>35.723147</td>\n",
       "      <td>34.468888</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.736649</td>\n",
       "      <td>0.719719</td>\n",
       "      <td>0.729555</td>\n",
       "      <td>0.884336</td>\n",
       "      <td>0.868376</td>\n",
       "      <td>...</td>\n",
       "      <td>8789.566347</td>\n",
       "      <td>0.397950</td>\n",
       "      <td>0.385886</td>\n",
       "      <td>0.379713</td>\n",
       "      <td>0.383286</td>\n",
       "      <td>0.630833</td>\n",
       "      <td>0.621197</td>\n",
       "      <td>0.616208</td>\n",
       "      <td>0.619101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>24.763480</td>\n",
       "      <td>27.562425</td>\n",
       "      <td>30.296392</td>\n",
       "      <td>30.427420</td>\n",
       "      <td>0.763669</td>\n",
       "      <td>0.737159</td>\n",
       "      <td>0.711539</td>\n",
       "      <td>0.709845</td>\n",
       "      <td>0.902890</td>\n",
       "      <td>0.891914</td>\n",
       "      <td>...</td>\n",
       "      <td>7758.992010</td>\n",
       "      <td>0.501404</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.483433</td>\n",
       "      <td>0.483675</td>\n",
       "      <td>0.708099</td>\n",
       "      <td>0.701688</td>\n",
       "      <td>0.695294</td>\n",
       "      <td>0.695468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>17.524107</td>\n",
       "      <td>23.831899</td>\n",
       "      <td>22.727791</td>\n",
       "      <td>19.619490</td>\n",
       "      <td>0.844352</td>\n",
       "      <td>0.787674</td>\n",
       "      <td>0.797552</td>\n",
       "      <td>0.825200</td>\n",
       "      <td>0.931279</td>\n",
       "      <td>0.906543</td>\n",
       "      <td>...</td>\n",
       "      <td>5002.969961</td>\n",
       "      <td>0.494479</td>\n",
       "      <td>0.475111</td>\n",
       "      <td>0.478560</td>\n",
       "      <td>0.488824</td>\n",
       "      <td>0.703192</td>\n",
       "      <td>0.689283</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.699159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dissimilarity_0  dissimilarity_45  dissimilarity_90  dissimilarity_135  \\\n",
       "0          36.022545         37.420513         28.835832          34.987897   \n",
       "1          21.824324         22.505369         18.579508          21.504477   \n",
       "2          27.298588         28.204032         23.367413          26.434295   \n",
       "3          43.113767         41.475130         36.150976          43.111441   \n",
       "4          46.773281         46.187211         45.491846          49.994699   \n",
       "..               ...               ...               ...                ...   \n",
       "155        21.459527         23.200347         27.332451          27.909334   \n",
       "156         8.840554         11.883463         12.704092          11.241469   \n",
       "157        29.494681         33.564682         35.723147          34.468888   \n",
       "158        24.763480         27.562425         30.296392          30.427420   \n",
       "159        17.524107         23.831899         22.727791          19.619490   \n",
       "\n",
       "     correlation_0  correlation_45  correlation_90  correlation_135  \\\n",
       "0         0.605575        0.591226        0.684692         0.617800   \n",
       "1         0.828589        0.823273        0.854096         0.831132   \n",
       "2         0.738198        0.729687        0.775990         0.746654   \n",
       "3         0.655680        0.668513        0.711100         0.655432   \n",
       "4         0.626393        0.631317        0.636999         0.600923   \n",
       "..             ...             ...             ...              ...   \n",
       "155       0.830504        0.816781        0.784110         0.779593   \n",
       "156       0.929968        0.905865        0.899329         0.910951   \n",
       "157       0.768559        0.736649        0.719719         0.729555   \n",
       "158       0.763669        0.737159        0.711539         0.709845   \n",
       "159       0.844352        0.787674        0.797552         0.825200   \n",
       "\n",
       "     homogeneity_0  homogeneity_45  ...  contrast_135     ASM_0    ASM_45  \\\n",
       "0         0.858737        0.853255  ...   8921.913788  0.520537  0.515794   \n",
       "1         0.914416        0.911745  ...   5483.641666  0.422439  0.420140   \n",
       "2         0.892948        0.889398  ...   6740.745118  0.495497  0.492460   \n",
       "3         0.830929        0.837355  ...  10993.417514  0.368477  0.373147   \n",
       "4         0.816578        0.818876  ...  12748.648332  0.359264  0.360401   \n",
       "..             ...             ...  ...           ...       ...       ...   \n",
       "155       0.915846        0.909020  ...   7116.880096  0.426427  0.420723   \n",
       "156       0.965332        0.953399  ...   2866.574569  0.471493  0.460515   \n",
       "157       0.884336        0.868376  ...   8789.566347  0.397950  0.385886   \n",
       "158       0.902890        0.891914  ...   7758.992010  0.501404  0.492366   \n",
       "159       0.931279        0.906543  ...   5002.969961  0.494479  0.475111   \n",
       "\n",
       "       ASM_90   ASM_135  energy_0  energy_45  energy_90  energy_135  label  \n",
       "0    0.541067  0.522625  0.721482   0.718188   0.735573    0.722928      0  \n",
       "1    0.433072  0.423388  0.649953   0.648182   0.658082    0.650683      0  \n",
       "2    0.507685  0.497902  0.703916   0.701755   0.712520    0.705622      0  \n",
       "3    0.387611  0.368861  0.607023   0.610858   0.622584    0.607339      0  \n",
       "4    0.361970  0.351103  0.599386   0.600334   0.601639    0.592539      0  \n",
       "..        ...       ...       ...        ...        ...         ...    ...  \n",
       "155  0.407819  0.405956  0.653014   0.648632   0.638607    0.637147      1  \n",
       "156  0.457784  0.462804  0.686654   0.678613   0.676597    0.680297      1  \n",
       "157  0.379713  0.383286  0.630833   0.621197   0.616208    0.619101      1  \n",
       "158  0.483433  0.483675  0.708099   0.701688   0.695294    0.695468      1  \n",
       "159  0.478560  0.488824  0.703192   0.689283   0.691781    0.699159      1  \n",
       "\n",
       "[160 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glcm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dissimilarity_0', 'dissimilarity_45', 'dissimilarity_90',\n",
       "       'dissimilarity_135', 'correlation_0', 'correlation_45',\n",
       "       'correlation_90', 'correlation_135', 'homogeneity_0', 'homogeneity_45',\n",
       "       'homogeneity_90', 'homogeneity_135', 'contrast_0', 'contrast_45',\n",
       "       'contrast_90', 'contrast_135', 'ASM_0', 'ASM_45', 'ASM_90', 'ASM_135',\n",
       "       'energy_0', 'energy_45', 'energy_90', 'energy_135', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glcm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = glcm_df[['dissimilarity_0', 'dissimilarity_45', 'dissimilarity_90',\n",
    "       'dissimilarity_135', 'correlation_0', 'correlation_45',\n",
    "       'correlation_90', 'correlation_135', 'homogeneity_0', 'homogeneity_45',\n",
    "       'homogeneity_90', 'homogeneity_135', 'contrast_0', 'contrast_45',\n",
    "       'contrast_90', 'contrast_135', 'ASM_0', 'ASM_45', 'ASM_90', 'ASM_135',\n",
    "       'energy_0', 'energy_45', 'energy_90', 'energy_135']]\n",
    "Y = glcm_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['RBF', 'Sigmoid','Linear']\n",
    "def chooseKernel(ker):\n",
    "  if (ker == 0):\n",
    "      return SVC(kernel = 'rbf', gamma = \"auto\")\n",
    "  elif (ker == 1):\n",
    "      return SVC(kernel = 'sigmoid', gamma = \"auto\")\n",
    "  elif (ker == 2):\n",
    "      return SVC(kernel = 'linear', gamma = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: RBF kernel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64        15\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.47        32\n",
      "   macro avg       0.23      0.50      0.32        32\n",
      "weighted avg       0.22      0.47      0.30        32\n",
      "\n",
      "Evaluation: Sigmoid kernel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.41      1.00      0.58        13\n",
      "\n",
      "    accuracy                           0.41        32\n",
      "   macro avg       0.20      0.50      0.29        32\n",
      "weighted avg       0.17      0.41      0.23        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91852\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\91852\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Linear kernel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.53      0.51        17\n",
      "           1       0.43      0.40      0.41        15\n",
      "\n",
      "    accuracy                           0.47        32\n",
      "   macro avg       0.46      0.46      0.46        32\n",
      "weighted avg       0.47      0.47      0.47        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix   \n",
    "for i in range(3):\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20)\n",
    "  svc_classifier = chooseKernel(i)\n",
    "  svc_classifier.fit(X_train, Y_train)\n",
    "  predictions = svc_classifier.predict(X_test)\n",
    "  print(\"Evaluation:\", kernels[i], \"kernel\")\n",
    "  print(classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 18.30342336\n",
      "Iteration 2, loss = 18.30342329\n",
      "Iteration 3, loss = 18.30342323\n",
      "Iteration 4, loss = 18.30342318\n",
      "Iteration 5, loss = 18.30342314\n",
      "Iteration 6, loss = 18.30342311\n",
      "Iteration 7, loss = 18.30342309\n",
      "Iteration 8, loss = 18.13150323\n",
      "Iteration 9, loss = 17.18990815\n",
      "Iteration 10, loss = 14.52049618\n",
      "Iteration 11, loss = 17.47312530\n",
      "Iteration 12, loss = 17.50215660\n",
      "Iteration 13, loss = 17.65582244\n",
      "Iteration 14, loss = 17.68508774\n",
      "Iteration 15, loss = 17.70283870\n",
      "Iteration 16, loss = 17.70351845\n",
      "Iteration 17, loss = 17.69073447\n",
      "Iteration 18, loss = 17.67283308\n",
      "Iteration 19, loss = 17.63123840\n",
      "Iteration 20, loss = 17.29942299\n",
      "Iteration 21, loss = 16.45005969\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=8, learning_rate_init=0.01, random_state=5,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANN\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(8), random_state=5, verbose=True, learning_rate_init=0.01)\n",
    "mlp_classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 9]\n",
      " [9 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        18\n",
      "           1       0.36      0.36      0.36        14\n",
      "\n",
      "    accuracy                           0.44        32\n",
      "   macro avg       0.43      0.43      0.43        32\n",
      "weighted avg       0.44      0.44      0.44        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_mlp=mlp_classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,predictions_mlp)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 9]\n",
      " [9 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        18\n",
      "           1       0.36      0.36      0.36        14\n",
      "\n",
      "    accuracy                           0.44        32\n",
      "   macro avg       0.43      0.43      0.43        32\n",
      "weighted avg       0.44      0.44      0.44        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive bayes \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=0.2)\n",
    "model  = GaussianNB()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred\n",
    "accuracy  = accuracy_score(Y_test,Y_pred)*100\n",
    "accuracy\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  4]\n",
      " [ 6  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72        17\n",
      "           1       0.69      0.60      0.64        15\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.69      0.68      0.68        32\n",
      "weighted avg       0.69      0.69      0.69        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
